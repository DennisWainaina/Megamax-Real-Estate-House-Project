{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 2 FINAL PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INTRODUCTION\n",
    "**Megamax Real Estate Agency** a well known Real Estate Agency in New York has decided to start a new division which connects home sellors to potential buyers for a small fee. It wants to find out how home rennovations may affect the **saleprices** of the homes of potential sellors. This is to advise potential sellors appropiately, to increase market appeal of their houses.\n",
    "\n",
    "**Megamax Real Estate Agency** has decided to hire you as a Data Scientist to predict how rennovations may affect the price of a house. After analysis, you are to present your findings and insights to the head of the new division, who will use both to see how rennovations will affect the saleprice of the home of a potential sellor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBJECTIVES\n",
    "The objectives of the project are:\n",
    "- To determine how rennovations affect the saleprice of the home of a potential sellor.\n",
    "- To present findings and model to head of division so that the head may use the insights generated to advise potential sellors(clients)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUSINESS UNDERSTANDING\n",
    "#### PROBLEM STATEMENT\n",
    "To determine the effect of home rennovations on the saleprice of a home. This is to help Megamax Real Estate Agency in making informed decisions to potential sellors of homes who are their clients.\n",
    "\n",
    "#### MEASUREMENT OF SUCCESS\n",
    "The goal is to determine the effect of home rennovations on the saleprice of homes. The measure of success will therefore be after analysis has been done and insights generated,findings should be presented to the head of the new divisions who will use both to advise new sellors appropiately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA UNDERSTANDING\n",
    "For the problem at hand the data used to see the effect of rennovations on the price of houses was the King County House Sales dataset. This dataset was sourced from Kaggle and is relevant to the problem at hand as it contains data about relevant features of houses together with the price of such homes. These features are in the form of columns in a dataframe and they include:\n",
    "\n",
    "- **Price** : This is the target(dependent) variable and is what we want to see the effect of rennovations on.\n",
    "\n",
    "- **Bedrooms**: This is the number of bedrooms a house has and is one of the rennovations that may be performed to see the effect of SalePrice such that one may add or remove bedrooms to see the effect on SalePrice.\n",
    "\n",
    "- **Floors**: This is the number of floors a house has and is relevant to the problem as a potential sellor may want to know the effect of adding or removing floors may have on the selling price of his/her home.\n",
    "\n",
    "- **Condition**: This is the overall condition which has unique values as follows ['Average', 'Very Good', 'Good', 'Poor', 'Fair']. It is relevant to our problem as the client may want to know whether rennovation of the house to make it look new will increase or decrease the selling price of the house.\n",
    "\n",
    "- **sqft_above**: This is the overall square footage of the house minus the basement. It is relevant as this factor shows whether the size of the house minus the basement determines its selling price. A client with enough land may even decide to increase its size to see if it will increase its asking price.\n",
    "\n",
    "- **waterfront**: This is the prescence of a waterfront in front of the house. A client may want to know whether adding a waterfront will decrease or increase the selling price of his/her home.\n",
    "\n",
    "- **grade**: This is the type and quality of the material used in construction of houses. It also includes the finishing and the design quality of the house and the interiors. It is relevant to the problem as a client may want to know whether using high quality materials in the rennovation of his/ her house will lead to increase or decrease in the price of the house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPARATION\n",
    "\n",
    "Before data is used for analysis one must ensure the data is clean. This is by:\n",
    "\n",
    "- **Removing outliers**: Identification and removal of data points that deviate significantly from the overall distribution, as they can adversely impact analysis results.\n",
    "\n",
    "- **Handling missing values**: Thoroughly checking for missing values and employing appropriate strategies to handle them, such as imputation techniques or assessing the suitability of the missing data for analysis.\n",
    "\n",
    "- **Identifying and resolving duplicates**: Identifying and removing duplicate records to ensure data integrity and avoid bias in analysis outcomes.\n",
    "\n",
    "- **Assessing columns with excessive missing values**: Evaluating columns with a substantial number of missing values and determining their relevance to the analysis. Dropping columns that are not essential or exploring alternative strategies for handling missing data.\n",
    "\n",
    "\n",
    "- **Correcting data types**: Verifying and correcting the data types of variables to align them with their intended representation (e.g., converting numerical data from strings to numeric types).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This was done by first loading important libraries that will be used for data preparation and for this project.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data is then loaded to see how the dataset looks like**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data = pd.read_csv('data/kc_house_data.csv')\n",
    "house_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking the general info of the dataframe such as the datatypes of each column and whether or not each column has missing values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at general info of the dataframe missing values and the dtypes of each column in the dataframe\n",
    "house_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Several columns have missing values so now the task is to check the percentage of missing values for each column in the dataframe so as to know what to handle these missing values**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking percentage of missing values in every column in the dataframe and putting values in a dictionary then a dataframe\n",
    "# Also creates a new column for the datatype of the columns.\n",
    "def missing_percentage(df):\n",
    "\n",
    "    # Dictionary for putting percentage of missing values\n",
    "    missing_values_percentage = {}\n",
    "    \n",
    "    # Loop for calculating percentage of missing values and putting values in dictionary\n",
    "    for column in df.columns:\n",
    "        missing_values_percentage[column] = df[column].isnull().sum() / len(df[column]) * 100\n",
    "\n",
    "    # Creating dataframe of the dictionary\n",
    "    missing_df = pd.Series(missing_values_percentage)\n",
    "    missing_df = pd.DataFrame(missing_df, columns=['Percentage Missing'])\n",
    "\n",
    "\n",
    "    # Creating a new column for the dtype of the column with missing values.\n",
    "    missing_df['dtype'] = [df[column].dtypes for column in missing_df.index]\n",
    "\n",
    "    return missing_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a copy of the house data dataframe to see if the function to check the percentage of missing values in the dataframe works before proceeding to apply it to the actual dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy of data to test our new function.\n",
    "X_test = house_data.copy()\n",
    "\n",
    "# Testing\n",
    "missing_percentage(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now applying the same function to the actual dataset to see the percentage of missing values for each column in the dataframe**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentage(house_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It appears the **view**, **waterfront** and **yr_renovated** columns have missing data we shall deal with each individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the view column only 0.291707% of its data is missing so we can just drop the rows with missing values.\n",
    "house_data.dropna(subset='view', inplace=True)\n",
    "\n",
    "# Checking to see if it worked\n",
    "house_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The view column no longer has missing values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the waterfront column we want to see if the presence of a waterfront does indeed affect the price of the house so will create two copies of the dataframe one which we fill missing values with yes and the other we fill with no to see what happens starting with no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin with creating a copy of the dataframe which we fill missing values with no.\n",
    "no_df = house_data.copy()\n",
    "\n",
    "# Filling missing values with the mode which was no.\n",
    "no_df['waterfront'].fillna(no_df['waterfront'].mode()[0], inplace=True)\n",
    "\n",
    "# Checking to see if it worked\n",
    "no_df.isnull().sum()  # It worked\n",
    "\n",
    "# Converting waterfront to numerical data\n",
    "no_df['waterfront'] = pd.factorize(no_df['waterfront'])[0]\n",
    "\n",
    "# Checking the correlation with a majority of no values.\n",
    "np.corrcoef(no_df['waterfront'], no_df['price'])[0][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the majority of values being no the correlation between the column waterfront and the column price is **0.0754613848461221** now lets see if we fill the missing values with yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_df = house_data.copy()\n",
    "\n",
    "# Filling missing values with the mode which was no.\n",
    "yes_df['waterfront'].fillna('yes', inplace=True)\n",
    "\n",
    "# Checking to see if it worked\n",
    "yes_df.isnull().sum()  # It worked\n",
    "\n",
    "# Converting waterfront to numerical data\n",
    "yes_df['waterfront'] = pd.factorize(yes_df['waterfront'])[0]\n",
    "\n",
    "# Checking the correlation with a majority of no values.\n",
    "np.corrcoef(yes_df['waterfront'], yes_df['price'])[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since either way there seems to be no change in the correlation we shall proceed to fill missing values of the waterfront with the mode of the column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data['waterfront'].fillna(house_data['waterfront'].mode()[0], inplace=True)\n",
    "\n",
    "# Checking to see if it worked\n",
    "house_data.isnull().sum()  # It worked now only the yr_renovated column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we deal with the yr_renovated column which has **3830** missing values. Which is **17.789508%** of its data missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step so as to know how to deal with the missing valuesis to draw a scatter plot of Price against yr_renovated. This will help us see if there's a correlation between year renovated and the price so that we can see the effect of missing values on that correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data.plot.scatter(x='yr_renovated', y='price', c='green');\n",
    "plt.title('Scatter plot before dealing with missing values');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There seems to be no correlation between the yr_renovated and the price of the house let us see what happens if we fill it with the mean.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a copy before doing it on the actual dataframe.\n",
    "test_data = house_data.copy()\n",
    "\n",
    "# We now filling missing values of this copy of the dataframe with the mean to see what happens to the correlation between the two.\n",
    "test_data['yr_renovated'].fillna(test_data['yr_renovated'].mean(), inplace=True)\n",
    "\n",
    "# Seeing if the original dataframe was affected.\n",
    "house_data.isnull().sum()  # No effect.\n",
    "\n",
    "# Plotting scatter plot with test data.\n",
    "test_data.plot.scatter(x='yr_renovated', y='price', c='green')\n",
    "plt.title('Scatter Plot after filling with mean');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filling with the missing values with mean seems to have no effect on the correlation between the yr_renovated column and the price column let us see what happens if we fill with the mode.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating copy\n",
    "new_test_data = house_data.copy()\n",
    "\n",
    "# Filling copy with mode of column\n",
    "new_test_data['yr_renovated'].fillna(new_test_data['yr_renovated'].mode()[0], inplace=True)\n",
    "\n",
    "# Checking to see if missing values of copy have been filled\n",
    "new_test_data.isnull().sum()\n",
    "\n",
    "# Plotting scatter plot\n",
    "new_test_data.plot.scatter(x='yr_renovated', y='price', c='green')\n",
    "plt.title('Scatter Plot after filling with mode');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The reason why we chose to see the effects of filling the missing values with mean or mode is we wanted to see if there's a correlation between the independent variable and the dependent variable and if filling missing values with mean or mode would have an effect on this correlation. There however seems to be no correlation between the two, so even if we fill with the mean, which we'll do it should have no effect on the relationship between the independent and dependent variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values of 'yr_renovated' column with the mean of the values.\n",
    "house_data['yr_renovated'].fillna(house_data['yr_renovated'].mean(), inplace=True)\n",
    "\n",
    "# Seeing if it worked\n",
    "house_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The missing values have been dealt with we now want to check for wrong datatypes as part of the data preparation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This we will do by creating a function that checks for wrong datatypes in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking for wrong datatypes in each column in the dataframe.\n",
    "\n",
    "def wrong_data(df):\n",
    "    # Dictionary for mapping\n",
    "    value_types = {\n",
    "        'int64': int,\n",
    "        'object': str,\n",
    "        'float64': float\n",
    "    }\n",
    "    # Dictionary for mapping columns with wrong datatypes\n",
    "    wrong_data_types = {}\n",
    "\n",
    "    # Loop which checks for every column in the dataframe if it has wrong datatypes.\n",
    "    for column in df.columns:\n",
    "        wrong_data_types[column] = [x for x in df[column] if type(x) != value_types[str(df[column].dtypes)]]\n",
    "\n",
    "    # Final results\n",
    "    return wrong_data_types\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After creating our function we test it on our dataframe **house_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing our function on a copy of the data\n",
    "wrong_data(house_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There appears to be no wrong datatypes in our house dataset the next is to deal with outliers in the data we shall do this by creating a function to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to see how the dependent variable loooks before outliers are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of price before removing outliers\n",
    "sns.histplot(house_data['price'], kde=True, bins=20)\n",
    "plt.title('Histogram of SalePrices before Standardization');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before outliers are removed the graph appears to be left skewed with majority of the data on the left side.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since outliers can only be checked and removed on numeric variables we will seperate the numeric and categorical variables to deal with the numeric variables seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of the dataframe to remove outliers to see if it works before applying to our real data.\n",
    "X_test = house_data.copy()\n",
    "\n",
    "# Isolating numeric variables\n",
    "numeric_variables = X_test.select_dtypes(include=np.number).columns.to_list()\n",
    "\n",
    "numeric_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking outliers in a dataframe removing them and creating a new dataframe without outliers\n",
    "def outliers(df):\n",
    "\n",
    "    # Dictionary for placing no. of outliers and the column name.\n",
    "    outliers_dict = {}\n",
    "    standardized_dict = {}\n",
    "\n",
    "    # For loop for checking outliers in every column in the dataframe.\n",
    "    for column in df.columns:\n",
    "        # Lower quantile\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "\n",
    "        # Upper Quantile\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "\n",
    "        # Finding IQR\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Defining lower and upper bound\n",
    "        lower_bound = Q1 - (1.5 * IQR)\n",
    "        upper_bound = Q3 + (1.5 * IQR)\n",
    "\n",
    "        # Finding outliers\n",
    "        outliers = df[column][(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "        outliers_dict[column] = 'The number of outliers is', len(outliers)\n",
    "\n",
    "        # Data without outliers\n",
    "        standardized_numvotes = df[column][(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "        \n",
    "        # Putting standardized values in a dict\n",
    "        standardized_dict[column] = standardized_numvotes\n",
    "\n",
    "    \n",
    "    standardized_df = pd.DataFrame(standardized_dict)  \n",
    "\n",
    "    # Results\n",
    "    return standardized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating our function for removing outliers we can now test it on a copy of the dataframe **X_test** to see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = outliers(X_test[numeric_variables])\n",
    "\n",
    "# Histogram of price after removing outliers.\n",
    "sns.histplot(new_df['price'], kde=True, color='green', bins='auto')\n",
    "plt.title('Histogram of SalePrices after removing outliers');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After removing outliers it appears the data for the SalePrice appears to be almost following a bell curve**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(new_df['yr_built'], kde=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
